{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_modelling with nmf and  SVD.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dSzW5KeOfOaG",
        "Aix9PymXptzH"
      ],
      "authorship_tag": "ABX9TyM/kcu/Ju8/vYnig7Rg4h+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parikshit23/Computational-Linear-Algebra/blob/master/topic_modelling_with_nmf_and_SVD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCZKTdBETryU",
        "colab_type": "text"
      },
      "source": [
        "#  Topic Modeling with NMF and SVD\n",
        "We'll take a set of documents in several different categories and find topics(consisting of group of words) for them. Knowing the actual categories helps us evaluate if the topics we find make sense\n",
        "\n",
        "We will try this with two different matrix factorizations: <b>Singular value Decomposition (SVD) </b> and <b> Non negative Matrix Factorization (NMF) </b> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgx8hDRRRKSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn import decomposition\n",
        "from scipy import linalg\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgO3VQ_0YeXo",
        "colab_type": "text"
      },
      "source": [
        "## Setting up the data\n",
        "\n",
        "Scikit Learn comes with a number of built-in datasets, as well as loading utilities to load several standard external datasets. We will be using the newsgroups dataset.\n",
        "\n",
        "Newsgroups are discussion groups on Usenet, which was popular in the 80s and 90s before the web really took off. This dataset includes 18,000 newsgroups posts with 20 topics.\n",
        "\n",
        "We will use only 4 categories out of the 20. This can be done by specifying the categories we want to use as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBR3-V_xYRRP",
        "colab_type": "code",
        "outputId": "2b7b3747-05ee-4445-b573-bd992eb0b9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "remove = ('headers', 'footers', 'quotes')\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNIWGHs1j09y",
        "colab_type": "text"
      },
      "source": [
        "Lets look how is the data structured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbQ0roxUXtEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abba1703-3160-4e3e-83be-b05ba0c14194"
      },
      "source": [
        "# Keys of the data\n",
        "newsgroups_train.keys()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr5ANthDhPSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9fc5bb04-6fab-4325-8bfb-ff9af25ee3b1"
      },
      "source": [
        "# how are the posts stored\n",
        "newsgroups_train.data[:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\",\n",
              " '\\n\\nSeems to be, barring evidence to the contrary, that Koresh was simply\\nanother deranged fanatic who thought it neccessary to take a whole bunch of\\nfolks with him, children and all, to satisfy his delusional mania. Jim\\nJones, circa 1993.\\n\\n\\nNope - fruitcakes like Koresh have been demonstrating such evil corruption\\nfor centuries.',\n",
              " \"\\n >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \\n\\nMB>                                                             So the\\nMB> 1970 figure seems unlikely to actually be anything but a perijove.\\n\\nJG>Sorry, _perijoves_...I'm not used to talking this language.\\n\\nCouldn't we just say periapsis or apoapsis?\\n\\n \",\n",
              " 'I have a request for those who would like to see Charley Wingate\\nrespond to the \"Charley Challenges\" (and judging from my e-mail, there\\nappear to be quite a few of you.)  \\n\\nIt is clear that Mr. Wingate intends to continue to post tangential or\\nunrelated articles while ingoring the Challenges themselves.  Between\\nthe last two re-postings of the Challenges, I noted perhaps a dozen or\\nmore posts by Mr. Wingate, none of which answered a single Challenge.  \\n\\nIt seems unmistakable to me that Mr. Wingate hopes that the questions\\nwill just go away, and he is doing his level best to change the\\nsubject.  Given that this seems a rather common net.theist tactic, I\\nwould like to suggest that we impress upon him our desire for answers,\\nin the following manner:\\n\\n1. Ignore any future articles by Mr. Wingate that do not address the\\nChallenges, until he answers them or explictly announces that he\\nrefuses to do so.\\n\\n--or--\\n\\n2. If you must respond to one of his articles, include within it\\nsomething similar to the following:\\n\\n    \"Please answer the questions posed to you in the Charley Challenges.\"\\n\\nReally, I\\'m not looking to humiliate anyone here, I just want some\\nhonest answers.  You wouldn\\'t think that honesty would be too much to\\nask from a devout Christian, would you?  \\n\\nNevermind, that was a rhetorical question.',\n",
              " 'AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\\nMay 7th  at Crystal City Virginia, under the auspices of AIAA.\\n\\nDoes anyone know more about this?  How much, to attend????\\n\\nAnyone want to go?',\n",
              " '\\nThere are definitely quite a few horrible deaths as the result of both\\natheists AND theists.  I\\'m sure Bobby can list quite a few for the atheist\\nside but fails to recognize that the theists are equally proficient at\\ngenocide.  Perhaps, since I\\'m a bit weak on history, somone here would like\\nto give a list of wars caused/led by theists?  I can think of a few (Hitler\\nclaimed to be a Christian for example) but a more complete list would\\nprobably be more effective in showing Bobby just how absurd his statement\\nis.\\n\\n\\nOn a side note, I notice you always sign your posts \"Peace\".  Perhaps you\\nshould take your own advice and leave the atheists in peace with their\\nbeliefs?\\n\\n\\nNanci',\n",
              " 'Mark Prado\\n  \\n  \\nOld pioneer song from the 1850\\'s or so goes as follows:\\n  \\n  \"In a cavern, in a canyon,\\n   Excavating for a mine,\\n   Dwelt a miner, forty-niner,\\n   And his daughter, CLEMENTINE\"\\n  \\nChorus:\\n  \"Oh my darling, Oh my darling,\\n   Oh my darling Clementine.\\n   You are lost and gone forever,\\n   Oh my darling Clementine.\"\\n  \\n I\\'ve also had it explained (but not confirmed from a reliable data\\nsource) that CLEMENTINE is an acronym.  Something like Combined\\nLunar Elemental Mapper Experiment on Extended Non Terrestrial\\nIntercept Near Earth.  Personally, I think that acronym was made up\\nto fit the name (if it really is an acronym).\\n ------------------------------------------------------------------\\n Wales Larrison                           Space Technology Investor',\n",
              " \"\\nAcorn Replay running on a 25MHz ARM 3 processor (the ARM 3 is about 20% slower\\nthan the ARM 6) does this in software (off a standard CD-ROM). 16 bit colour at\\nabout the same resolution (so what if the computer only has 8 bit colour\\nsupport, real-time dithering too...). The 3D0/O is supposed to have a couple of\\nDSPs - the ARM being used for housekeeping.\\n\\n\\nA 25MHz ARM 6xx should clock around 20 ARM MIPS, say 18 flat out. Depends\\nreally on the surrounding system and whether you are talking ARM6x or ARM6xx\\n(the latter has a cache, and so is essential to run at this kind of speed with\\nslower memory).\\n\\nI'll stop saying things there 'cos I'll hopefully be working for ARM after\\ngraduation...\\n\\nMike\\n\\nPS Don't pay heed to what reps from Philips say; if the 3D0/O doesn't beat the\\n   pants off 3DI then I'll eat this postscript.\",\n",
              " '\\nTheir Hiten engineering-test mission spent a while in a highly eccentric\\nEarth orbit doing lunar flybys, and then was inserted into lunar orbit\\nusing some very tricky gravity-assist-like maneuvering.  This meant that\\nit would crash on the Moon eventually, since there is no such thing as\\na stable lunar orbit (as far as anyone knows), and I believe I recall\\nhearing recently that it was about to happen.',\n",
              " \"I'm interested in find out what is involved in processing pairs of \\nstereo photographs.  I have black-and-white photos and would like \\nto obtain surface contours.\\n\\nI'd prefer to do the processing on an SGI, but would be interested\\nin hearing what software/hardware is used for this type of\\nimage processing.\\n\\nPlease email and/or post to comp.sys.sgi.graphics your responses.\\n\\nThanks,\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evqZm-irhPPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "285dd45b-5d11-4651-da89-9584cd14e6b3"
      },
      "source": [
        "# how are the target_names stored\n",
        "newsgroups_train.target_names[:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrg-b5OchPLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "4683b3b0-f235-4de9-bb62-135662f12449"
      },
      "source": [
        "# how are the target stored\n",
        "newsgroups_train.data[:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\",\n",
              " '\\n\\nSeems to be, barring evidence to the contrary, that Koresh was simply\\nanother deranged fanatic who thought it neccessary to take a whole bunch of\\nfolks with him, children and all, to satisfy his delusional mania. Jim\\nJones, circa 1993.\\n\\n\\nNope - fruitcakes like Koresh have been demonstrating such evil corruption\\nfor centuries.',\n",
              " \"\\n >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \\n\\nMB>                                                             So the\\nMB> 1970 figure seems unlikely to actually be anything but a perijove.\\n\\nJG>Sorry, _perijoves_...I'm not used to talking this language.\\n\\nCouldn't we just say periapsis or apoapsis?\\n\\n \",\n",
              " 'I have a request for those who would like to see Charley Wingate\\nrespond to the \"Charley Challenges\" (and judging from my e-mail, there\\nappear to be quite a few of you.)  \\n\\nIt is clear that Mr. Wingate intends to continue to post tangential or\\nunrelated articles while ingoring the Challenges themselves.  Between\\nthe last two re-postings of the Challenges, I noted perhaps a dozen or\\nmore posts by Mr. Wingate, none of which answered a single Challenge.  \\n\\nIt seems unmistakable to me that Mr. Wingate hopes that the questions\\nwill just go away, and he is doing his level best to change the\\nsubject.  Given that this seems a rather common net.theist tactic, I\\nwould like to suggest that we impress upon him our desire for answers,\\nin the following manner:\\n\\n1. Ignore any future articles by Mr. Wingate that do not address the\\nChallenges, until he answers them or explictly announces that he\\nrefuses to do so.\\n\\n--or--\\n\\n2. If you must respond to one of his articles, include within it\\nsomething similar to the following:\\n\\n    \"Please answer the questions posed to you in the Charley Challenges.\"\\n\\nReally, I\\'m not looking to humiliate anyone here, I just want some\\nhonest answers.  You wouldn\\'t think that honesty would be too much to\\nask from a devout Christian, would you?  \\n\\nNevermind, that was a rhetorical question.',\n",
              " 'AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\\nMay 7th  at Crystal City Virginia, under the auspices of AIAA.\\n\\nDoes anyone know more about this?  How much, to attend????\\n\\nAnyone want to go?',\n",
              " '\\nThere are definitely quite a few horrible deaths as the result of both\\natheists AND theists.  I\\'m sure Bobby can list quite a few for the atheist\\nside but fails to recognize that the theists are equally proficient at\\ngenocide.  Perhaps, since I\\'m a bit weak on history, somone here would like\\nto give a list of wars caused/led by theists?  I can think of a few (Hitler\\nclaimed to be a Christian for example) but a more complete list would\\nprobably be more effective in showing Bobby just how absurd his statement\\nis.\\n\\n\\nOn a side note, I notice you always sign your posts \"Peace\".  Perhaps you\\nshould take your own advice and leave the atheists in peace with their\\nbeliefs?\\n\\n\\nNanci',\n",
              " 'Mark Prado\\n  \\n  \\nOld pioneer song from the 1850\\'s or so goes as follows:\\n  \\n  \"In a cavern, in a canyon,\\n   Excavating for a mine,\\n   Dwelt a miner, forty-niner,\\n   And his daughter, CLEMENTINE\"\\n  \\nChorus:\\n  \"Oh my darling, Oh my darling,\\n   Oh my darling Clementine.\\n   You are lost and gone forever,\\n   Oh my darling Clementine.\"\\n  \\n I\\'ve also had it explained (but not confirmed from a reliable data\\nsource) that CLEMENTINE is an acronym.  Something like Combined\\nLunar Elemental Mapper Experiment on Extended Non Terrestrial\\nIntercept Near Earth.  Personally, I think that acronym was made up\\nto fit the name (if it really is an acronym).\\n ------------------------------------------------------------------\\n Wales Larrison                           Space Technology Investor',\n",
              " \"\\nAcorn Replay running on a 25MHz ARM 3 processor (the ARM 3 is about 20% slower\\nthan the ARM 6) does this in software (off a standard CD-ROM). 16 bit colour at\\nabout the same resolution (so what if the computer only has 8 bit colour\\nsupport, real-time dithering too...). The 3D0/O is supposed to have a couple of\\nDSPs - the ARM being used for housekeeping.\\n\\n\\nA 25MHz ARM 6xx should clock around 20 ARM MIPS, say 18 flat out. Depends\\nreally on the surrounding system and whether you are talking ARM6x or ARM6xx\\n(the latter has a cache, and so is essential to run at this kind of speed with\\nslower memory).\\n\\nI'll stop saying things there 'cos I'll hopefully be working for ARM after\\ngraduation...\\n\\nMike\\n\\nPS Don't pay heed to what reps from Philips say; if the 3D0/O doesn't beat the\\n   pants off 3DI then I'll eat this postscript.\",\n",
              " '\\nTheir Hiten engineering-test mission spent a while in a highly eccentric\\nEarth orbit doing lunar flybys, and then was inserted into lunar orbit\\nusing some very tricky gravity-assist-like maneuvering.  This meant that\\nit would crash on the Moon eventually, since there is no such thing as\\na stable lunar orbit (as far as anyone knows), and I believe I recall\\nhearing recently that it was about to happen.',\n",
              " \"I'm interested in find out what is involved in processing pairs of \\nstereo photographs.  I have black-and-white photos and would like \\nto obtain surface contours.\\n\\nI'd prefer to do the processing on an SGI, but would be interested\\nin hearing what software/hardware is used for this type of\\nimage processing.\\n\\nPlease email and/or post to comp.sys.sgi.graphics your responses.\\n\\nThanks,\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZpLtlPmO0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e84ded9-e461-45c6-8982-df1f2e81796c"
      },
      "source": [
        "# What is DESCR are the target stored\n",
        "newsgroups_train.DESCR"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.. _20newsgroups_dataset:\\n\\nThe 20 newsgroups text dataset\\n------------------------------\\n\\nThe 20 newsgroups dataset comprises around 18000 newsgroups posts on\\n20 topics split in two subsets: one for training (or development)\\nand the other one for testing (or for performance evaluation). The split\\nbetween the train and test set is based upon a messages posted before\\nand after a specific date.\\n\\nThis module contains two loaders. The first one,\\n:func:`sklearn.datasets.fetch_20newsgroups`,\\nreturns a list of the raw texts that can be fed to text feature\\nextractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\\nwith custom parameters so as to extract feature vectors.\\nThe second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\\nreturns ready-to-use features, i.e., it is not necessary to use a feature\\nextractor.\\n\\n**Data Set Characteristics:**\\n\\n    =================   ==========\\n    Classes                     20\\n    Samples total            18846\\n    Dimensionality               1\\n    Features                  text\\n    =================   ==========\\n\\nUsage\\n~~~~~\\n\\nThe :func:`sklearn.datasets.fetch_20newsgroups` function is a data\\nfetching / caching functions that downloads the data archive from\\nthe original `20 newsgroups website`_, extracts the archive contents\\nin the ``~/scikit_learn_data/20news_home`` folder and calls the\\n:func:`sklearn.datasets.load_files` on either the training or\\ntesting set folder, or both of them::\\n\\n  >>> from sklearn.datasets import fetch_20newsgroups\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\')\\n\\n  >>> from pprint import pprint\\n  >>> pprint(list(newsgroups_train.target_names))\\n  [\\'alt.atheism\\',\\n   \\'comp.graphics\\',\\n   \\'comp.os.ms-windows.misc\\',\\n   \\'comp.sys.ibm.pc.hardware\\',\\n   \\'comp.sys.mac.hardware\\',\\n   \\'comp.windows.x\\',\\n   \\'misc.forsale\\',\\n   \\'rec.autos\\',\\n   \\'rec.motorcycles\\',\\n   \\'rec.sport.baseball\\',\\n   \\'rec.sport.hockey\\',\\n   \\'sci.crypt\\',\\n   \\'sci.electronics\\',\\n   \\'sci.med\\',\\n   \\'sci.space\\',\\n   \\'soc.religion.christian\\',\\n   \\'talk.politics.guns\\',\\n   \\'talk.politics.mideast\\',\\n   \\'talk.politics.misc\\',\\n   \\'talk.religion.misc\\']\\n\\nThe real data lies in the ``filenames`` and ``target`` attributes. The target\\nattribute is the integer index of the category::\\n\\n  >>> newsgroups_train.filenames.shape\\n  (11314,)\\n  >>> newsgroups_train.target.shape\\n  (11314,)\\n  >>> newsgroups_train.target[:10]\\n  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\\n\\nIt is possible to load only a sub-selection of the categories by passing the\\nlist of the categories to load to the\\n:func:`sklearn.datasets.fetch_20newsgroups` function::\\n\\n  >>> cats = [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\', categories=cats)\\n\\n  >>> list(newsgroups_train.target_names)\\n  [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train.filenames.shape\\n  (1073,)\\n  >>> newsgroups_train.target.shape\\n  (1073,)\\n  >>> newsgroups_train.target[:10]\\n  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\\n\\nConverting text to vectors\\n~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIn order to feed predictive or clustering models with the text data,\\none first need to turn the text into vectors of numerical values suitable\\nfor statistical analysis. This can be achieved with the utilities of the\\n``sklearn.feature_extraction.text`` as demonstrated in the following\\nexample that extract `TF-IDF`_ vectors of unigram tokens\\nfrom a subset of 20news::\\n\\n  >>> from sklearn.feature_extraction.text import TfidfVectorizer\\n  >>> categories = [\\'alt.atheism\\', \\'talk.religion.misc\\',\\n  ...               \\'comp.graphics\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       categories=categories)\\n  >>> vectorizer = TfidfVectorizer()\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> vectors.shape\\n  (2034, 34118)\\n\\nThe extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\\ncomponents by sample in a more than 30000-dimensional space\\n(less than .5% non-zero features)::\\n\\n  >>> vectors.nnz / float(vectors.shape[0])\\n  159.01327...\\n\\n:func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \\nreturns ready-to-use token counts features instead of file names.\\n\\n.. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\\n.. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\\n\\n\\nFiltering text for more realistic training\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIt is easy for a classifier to overfit on particular things that appear in the\\n20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\\nhigh F-scores, but their results would not generalize to other documents that\\naren\\'t from this window of time.\\n\\nFor example, let\\'s look at the results of a multinomial Naive Bayes classifier,\\nwhich is fast to train and achieves a decent F-score::\\n\\n  >>> from sklearn.naive_bayes import MultinomialNB\\n  >>> from sklearn import metrics\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.88213...\\n\\n(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\\nthe training and test data, instead of segmenting by time, and in that case\\nmultinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\\nyet of what\\'s going on inside this classifier?)\\n\\nLet\\'s take a look at what the most informative features are:\\n\\n  >>> import numpy as np\\n  >>> def show_top10(classifier, vectorizer, categories):\\n  ...     feature_names = np.asarray(vectorizer.get_feature_names())\\n  ...     for i, category in enumerate(categories):\\n  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\\n  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\\n  ...\\n  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\\n  alt.atheism: edu it and in you that is of to the\\n  comp.graphics: edu in graphics it is for and of to the\\n  sci.space: edu it that is in and space to of the\\n  talk.religion.misc: not it you in is that and to of the\\n\\n\\nYou can now see many things that these features have overfit to:\\n\\n- Almost every group is distinguished by whether headers such as\\n  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\\n- Another significant feature involves whether the sender is affiliated with\\n  a university, as indicated either by their headers or their signature.\\n- The word \"article\" is a significant feature, based on how often people quote\\n  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\\n  wrote:\"\\n- Other features match the names and e-mail addresses of particular people who\\n  were posting at the time.\\n\\nWith such an abundance of clues that distinguish newsgroups, the classifiers\\nbarely have to identify topics from text at all, and they all perform at the\\nsame high level.\\n\\nFor this reason, the functions that load 20 Newsgroups data provide a\\nparameter called **remove**, telling it what kinds of information to strip out\\nof each file. **remove** should be a tuple containing any subset of\\n``(\\'headers\\', \\'footers\\', \\'quotes\\')``, telling it to remove headers, signature\\nblocks, and quotation blocks respectively.\\n\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(pred, newsgroups_test.target, average=\\'macro\\')\\n  0.77310...\\n\\nThis classifier lost over a lot of its F-score, just because we removed\\nmetadata that has little to do with topic classification.\\nIt loses even more if we also strip this metadata from the training data:\\n\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                       categories=categories)\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.76995...\\n\\nSome other classifiers cope better with this harder version of the task. Try\\nrunning :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\\nthe ``--filter`` option to compare the results.\\n\\n.. topic:: Recommendation\\n\\n  When evaluating text classifiers on the 20 Newsgroups data, you\\n  should strip newsgroup-related metadata. In scikit-learn, you can do this by\\n  setting ``remove=(\\'headers\\', \\'footers\\', \\'quotes\\')``. The F-score will be\\n  lower because it is more realistic.\\n\\n.. topic:: Examples\\n\\n   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\\n\\n   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOBUIlwJaZ3f",
        "colab_type": "code",
        "outputId": "576e3948-e4ce-495a-abca-6ed6cc8d68b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "newsgroups_train.filenames.shape, newsgroups_train.target.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2034,), (2034,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isT_rl33bI3h",
        "colab_type": "text"
      },
      "source": [
        "Let's look at some of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPTCKoN3ZV_b",
        "colab_type": "code",
        "outputId": "6bd53a92-38cb-4852-a194-f941886cb86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "print('\\n'.join(newsgroups_train.data[:3]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "\n",
            "\n",
            "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
            "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
            "folks with him, children and all, to satisfy his delusional mania. Jim\n",
            "Jones, circa 1993.\n",
            "\n",
            "\n",
            "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
            "for centuries.\n",
            "\n",
            " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
            "\n",
            "MB>                                                             So the\n",
            "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
            "\n",
            "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
            "\n",
            "Couldn't we just say periapsis or apoapsis?\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2k_V9ESbma-",
        "colab_type": "code",
        "outputId": "5c24c749-288c-460d-8bde-b408223d755c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#What are the target names of the forst three posts\n",
        "np.array(newsgroups_train.target_names)[newsgroups_train.target[:3]]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['comp.graphics', 'talk.religion.misc', 'sci.space'], dtype='<U18')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seI1rBlGsY_B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ab26ee7-414e-4145-b8de-ef37805e59ac"
      },
      "source": [
        "newsgroups_train.target_names"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDLYI_0NcrV9",
        "colab_type": "text"
      },
      "source": [
        "The target attribute is the integer index of the category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYg1gZuRb77v",
        "colab_type": "code",
        "outputId": "f34da1e3-5d53-4620-c67d-d849465c1491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "newsgroups_train.target[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2ovsIipZepL",
        "colab_type": "text"
      },
      "source": [
        "## Countvectorizer\n",
        "Next, We want to extract the word counts for words occuring in all the posts.\n",
        "Scikit learn has a method that will extract all the word counts for us.\n",
        "The function Countvectorizer converts a collection of text documents to a matrix of token counts\n",
        "This implementation produces a sparse representation of the counts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUvsGfrJg3-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL2YxJqvhDJL",
        "colab_type": "code",
        "outputId": "ce8f3e76-3ce7-44a1-f744-ff547cf02941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data).todense() # (documents, vocab)\n",
        "vectors.shape #, vectors.nnz / vectors.shape[0], row_means.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 26576)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taX-o-mzkPeB",
        "colab_type": "code",
        "outputId": "1d963460-be78-495b-bd78-007de490b12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(newsgroups_train.data),vectors.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2034 (2034, 26576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsXqttShaAlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = np.array(vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxlWkO2kaAns",
        "colab_type": "code",
        "outputId": "43a7679b-4be9-4f4b-d110-9f1255c6f635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26576,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EE4UPohaAqg",
        "colab_type": "code",
        "outputId": "299c1446-c73d-42ab-a6fc-cfae29ae8e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "vocab[7000:7020]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cosmonauts', 'cosmos', 'cosponsored', 'cost', 'costa', 'costar',\n",
              "       'costing', 'costly', 'costruction', 'costs', 'cosy', 'cote',\n",
              "       'couched', 'couldn', 'council', 'councils', 'counsel',\n",
              "       'counselees', 'counselor', 'count'], dtype='<U80')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGFPGa-esl5E",
        "colab_type": "text"
      },
      "source": [
        "## Singular Value Decomposition (SVD)\n",
        "\n",
        "Singular Value Decomposition is a dimentionality reduction technique. \n",
        "A matrix when decomposed by SVD gives three following matrices as outputs <br> \n",
        "\n",
        "U = A left orthogonal matrix <br>\n",
        "s = A singular matrix (only diagonal elements have values rest is zero)<br>\n",
        "Vh = A right Orthogonal matrix\n",
        "\n",
        "In this case the 2034x26576 vectors matrix (result of countvectorizer) is decomposed into three matrices as follows:<br>\n",
        "U is a 2034x2034 matrix <br>\n",
        "s is a singular matrix of height 2034 <br>\n",
        "Vh is a 2034X26576 matrix <br>\n",
        "\n",
        "The SVD functions as shown in the image below: <br>\n",
        "![alt text](https://raw.githubusercontent.com/parikshit23/Computational-Linear-Algebra/master/images/SVD.png) <br>\n",
        "\n",
        "Source:(<a href=\"https://research.fb.com/fast-randomized-svd/\">Facebook Research</a>)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHexSiJnb9j4",
        "colab_type": "text"
      },
      "source": [
        "linalg.svd is a scipy function which takes in the vectors matrix and decomposes it into 3 matrices as decribed above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8RmvRD9aAts",
        "colab_type": "code",
        "outputId": "a6f9d4dd-e01f-4585-bfd0-9e6b43682aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%time U, s, Vh = linalg.svd(vectors, full_matrices=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 11s, sys: 3.52 s, total: 1min 15s\n",
            "Wall time: 38.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bkk6TJNaAwR",
        "colab_type": "code",
        "outputId": "bb038d92-8c24-4cbd-da42-5b3394c1adef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(U.shape,s.shape,Vh.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2034, 2034) (2034,) (2034, 26576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1pCwVdrRKq7",
        "colab_type": "text"
      },
      "source": [
        "Confirming that this is a decomposition by subtracting the product of U,s,Vh from the original vectors matrix. <br>The difference between the 2 should be very close to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOqgH2CDaAy5",
        "colab_type": "code",
        "outputId": "88db049c-01da-4451-c36e-2a7cc8f4ad58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reconstructed_vectors = U @ np.diag(s) @Vh\n",
        "np.linalg.norm(reconstructed_vectors-vectors)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0400655704971045e-12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTb5nRA4RfgS",
        "colab_type": "text"
      },
      "source": [
        "Confirming if U, s, Vh is a decomposition of the Vectors <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udh9PvaJaA1P",
        "colab_type": "code",
        "outputId": "0abc555d-e3ad-4e50-a50b-389e81242ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reconstructed_vectors = U @ np.diag(s) @ Vh\n",
        "np.linalg.norm(reconstructed_vectors-vectors)\n",
        "np.allclose(reconstructed_vectors,vectors)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lAvVBUBR0dr",
        "colab_type": "text"
      },
      "source": [
        "Confriming that U,Vh are orthonormal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qRy_J7ReRrr",
        "colab_type": "code",
        "outputId": "417adbd3-9779-4e0b-eea5-0da111e0031a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.allclose(U @ U.T,np.eye(U.shape[0]))\n",
        "np.allclose(Vh @ Vh.T,np.eye(Vh.shape[0]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBHDWUPYfDvo",
        "colab_type": "text"
      },
      "source": [
        "### What can we say about singular values?\n",
        "\n",
        "The singular values indicate the importance. As seen below the importance drops of very quickly. After 125 values the reduction of the importance is very low. <br>\n",
        "\n",
        "This indicates that we can use the top 125 values and ignore the rest. Thus reducing the dimentionality \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vd0vUoYes15",
        "colab_type": "code",
        "outputId": "3b703ec0-1656-401d-8c64-b8df657c4ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(s)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8bb0a3d2e8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZH0lEQVR4nO3de5Ac51nv8e/TPXuTdnVfy4qkRHaiXFwUsR0lCEhSEB+M40BkLkmZwzkWOT5xUSSQVKCCIXU4UEUVMZyTHFxQBoNdkVOGJCSkrEoZEuM4mFMVX1a+23KstWNFkmVpraulvc7Mwx/9zmzPbq/2orn16Pepmpqet3tmHvWsfv3O2z3d5u6IiEhniVpdgIiI1J/CXUSkAyncRUQ6kMJdRKQDKdxFRDpQodUFAKxbt863bNnS6jJERHJlz549r7n7YNa8tgj3LVu2MDQ01OoyRERyxcz2zzVPwzIiIh1I4S4i0oEU7iIiHUjhLiLSgRTuIiIdSOEuItKBFO4iIh0o1+H+6MvH+cJ3fsBksdzqUkRE2kquw33P/hPc+t1himWFu4hIWq7D3cK9rjciIlIr3+Ee0l3ZLiJSK9/hXu27i4hIWq7DvULXgRURqZXrcNewjIhItlyHe4U67iIitXId7qauu4hIpnyHe7h3pbuISI18h3ul465sFxGpke9wD/fKdhGRWvkOd9Nx7iIiWXId7hU6zl1EpNaCw93MYjN73My+FR5fYmYPm9mwmX3VzLpDe094PBzmb2lM6TrOXURkLovpuX8K2Jt6fAvwRXd/C3ACuDG03wicCO1fDMs1hE4cJiKSbUHhbmabgA8Bfx8eG/AB4OthkV3AdWF6R3hMmH+VNWpwPLysDoUUEam10J77/wM+C1ROnL4WOOnuxfD4ILAxTG8EDgCE+afC8jXM7CYzGzKzoZGRkSUVX91iKNtFRGrMG+5m9gvAUXffU883dvfb3X2bu28bHBxc0mtozF1EJFthAcv8NPBhM7sW6AVWAH8JrDKzQuidbwIOheUPAZuBg2ZWAFYCx+peOdOn/NWYu4hIrXl77u7+B+6+yd23ANcD33X3XwceAH41LLYTuCdM7w6PCfO/6w06VnG65650FxFJO5/j3H8f+IyZDZOMqd8R2u8A1ob2zwA3n1+Jc9NPmEREsi1kWKbK3b8HfC9MvwS8J2OZceAjdahtEXU1891ERNpfrn+hqh2qIiLZ8h3u1R2qincRkbRchzs65a+ISKZch7t2qIqIZMt3uJuOcxcRyZLvcA/3Os5dRKRWvsNd4zIiIplyHe4VGpYREamV63DXce4iItnyHe46zl1EJFO+w109dxGRTLkO9wp13EVEauU63Kev3qd0FxFJy3e4h3v13EVEauU73HWcu4hIplyHe4U67iIitXId7rqGqohItnyHu66hKiKSKd/hHu7VcxcRqZXvcNfFOkREMuU63Ct9dw3LiIjUynW4q+cuIpIt3+He6gJERNpUrsNdRESy5TrcdQ1VEZFs+Q73cK8dqiIitfId7tqhKiKSqTPCvbVliIi0nXyHuy6zJyKSKdfhjnruIiKZch3uOreMiEi2fIe7rtYhIpIp1+E+TV13EZG0XIe7hmVERLLlO9y1Q1VEJFO+w12X2RMRyTRvuJtZr5k9YmZPmtmzZvYnof0SM3vYzIbN7Ktm1h3ae8Lj4TB/S6OKn/6FqtJdRCRtIT33CeAD7v5O4HLgGjPbDtwCfNHd3wKcAG4My98InAjtXwzLNcT0uWVERCRt3nD3xJnwsCvcHPgA8PXQvgu4LkzvCI8J86+yRh2zqHPLiIhkWtCYu5nFZvYEcBS4D3gROOnuxbDIQWBjmN4IHAAI808BazNe8yYzGzKzoZGRkSUVb7pch4hIpgWFu7uX3P1yYBPwHuDt5/vG7n67u29z922Dg4Pn91oamBERqbGoo2Xc/STwAPCTwCozK4RZm4BDYfoQsBkgzF8JHKtLtTOYBt1FRDIt5GiZQTNbFab7gJ8D9pKE/K+GxXYC94Tp3eExYf53vUGHsyjbRUSyFeZfhA3ALjOLSTYGX3P3b5nZc8BXzOxPgceBO8LydwBfNrNh4DhwfQPqBnSZPRGRucwb7u7+FHBFRvtLJOPvM9vHgY/Upbp5TP9CVekuIpKW81+oJtRzFxGple9w17llREQy5Trc0XHuIiKZch7uCZ1bRkSkVq7DXcMyIiLZ8h3ulQmlu4hIjXyHe+U4d6W7iEiNfId7uNeQu4hIrXyHu075KyKSKd/hXrnMXovrEBFpN/kOdx3mLiKSKdfhXqHj3EVEanVGuLe6ABGRNpPrcNcOVRGRbPkOd12uQ0QkU77DXT13EZFMnRHurS1DRKTt5Dvc0WX2RESy5DvcdZk9EZFM+Q73VhcgItKmch3uFRqWERGpletwr5zyt6x0FxGpketwL0RJuJfKCncRkbRch3scwr2ocBcRqZHrcC/E6rmLiGTJd7hHSfnquYuI1Mp5uIeee6nc4kpERNpLrsM9jjXmLiKSJdfhrqNlRESy5TrcdbSMiEi2fId7+BFTsaRwFxFJy3e4V4Zl9AtVEZEauQ53MyMyKGtYRkSkRq7DHZLeu3ruIiK1ch/ukZl67iIiM+Q+3AuR6WgZEZEZch/uUWQ6zl1EZIZ5w93MNpvZA2b2nJk9a2afCu1rzOw+M9sX7leHdjOzW81s2MyeMrMrG/kPiCPT+dxFRGZYSM+9CPyuu18GbAc+YWaXATcD97v7VuD+8Bjgg8DWcLsJuK3uVacU1HMXEZll3nB398Pu/liYfh3YC2wEdgC7wmK7gOvC9A7gLk88BKwysw11rzyITOEuIjLTosbczWwLcAXwMLDe3Q+HWa8C68P0RuBA6mkHQ9vM17rJzIbMbGhkZGSRZU+L1XMXEZllweFuZv3AN4BPu/vp9Dx3d2BRCevut7v7NnffNjg4uJin1ohMx7mLiMy0oHA3sy6SYL/b3f85NB+pDLeE+6Oh/RCwOfX0TaGtIQqxjnMXEZlpIUfLGHAHsNfdv5CatRvYGaZ3Avek2m8IR81sB06lhm/qLjYd5y4iMlNhAcv8NPDfgafN7InQ9ofA54GvmdmNwH7go2HevcC1wDAwCnysrhXPEOlQSBGRWeYNd3f//4DNMfuqjOUd+MR51rVgsY6WERGZJfe/UE2Olml1FSIi7aVDwl3pLiKSlvtwjyJDF2ISEamV+3CPdbEOEZFZch/uhSjSDlURkRlyH+5RhMJdRGSG3Ie7LrMnIjJb7sNdZ4UUEZkt9+Gu87mLiMyW+3CPo0jnlhERmSH34d4V60dMIiIz5T7c40hnhRQRmSn34a4xdxGR2XIf7nEUUdT5B0REauQ+3Ltio6gxdxGRGrkPd10gW0RkttyHe0E7VEVEZsl9uGvMXURkttyHe0Fj7iIis+Q/3DXmLiIyS0eEu8bcRURq5T7c4yjCXed0FxFJy324F2ID0Li7iEhK/sM9SsJdPXcRkWm5D/c4qvTcFe4iIhW5D/dKz13HuouITMt9uC/rKQBwemyqxZWIiLSP3If7xlV9ABw+Nd7iSkRE2kfuw32gN+m5n50otrgSEZH2kftwXx6GZc5OKtxFRCpyH+79IdzPqOcuIlKV+3Cv9twV7iIiVbkP92VdMQBnJkotrkREpH3kPtyjyFi/oocfvna21aWIiLSN3Ic7wKbVyzhxdrLVZYiItI2OCPdl3TGjOlpGRKRq3nA3szvN7KiZPZNqW2Nm95nZvnC/OrSbmd1qZsNm9pSZXdnI4iuScNeYu4hIxUJ67l8CrpnRdjNwv7tvBe4PjwE+CGwNt5uA2+pT5rkt7y7oOHcRkZR5w93dHwSOz2jeAewK07uA61Ltd3niIWCVmW2oV7Fz6euOGVPPXUSkaqlj7uvd/XCYfhVYH6Y3AgdSyx0MbbOY2U1mNmRmQyMjI0ssI7G8p8BZHQopIlJ13jtU3d2BRZ9v191vd/dt7r5tcHDwvGpY1h0zNlXSBTtERIKlhvuRynBLuD8a2g8Bm1PLbQptDbWsO/kh09iUeu8iIrD0cN8N7AzTO4F7Uu03hKNmtgOnUsM3DbOsOzkFgQ6HFBFJFOZbwMz+EfgZYJ2ZHQT+N/B54GtmdiOwH/hoWPxe4FpgGBgFPtaAmmdZ3pP03EcnSjDQjHcUEWlv84a7u//aHLOuyljWgU+cb1GL1del0/6KiKR1xC9UKz13HQ4pIpLoiHCvjLm/rtP+iogAHRLub1jVC8ArJ8daXImISHvoiHBfP9BLdyHiR8dGW12KiEhb6IhwjyJj8+o+9ivcRUSADgl3gIsGejl2dqLVZYiItIWOCXed9ldEZFrnhHtPQeEuIhJ0TLiv6+/m8KkxxnV+GRGRzgn3n33bRYxPlfn+i8daXYqISMt1TLj/+KaVALw4cqbFlYiItF7HhPvKvi4Gegr86LgOhxQR6ZhwNzM2r1mmcBcRoYPCHeAdG1bwyA+PU9YVmUTkAtdR4b790jWMTpZ49OWZ1/MWEbmwdFS4f+DtFwHwxIGTLa5ERKS1Oirc1/b3cNmGFXx9z0GS64aIiFyYOircAT7+/kvYd/QMu598pdWliIi0TMeF+4ffuZF3bFjBLf/yvK7MJCIXrI4L9zgy/teH3sErp8b5o3ueaXU5IiIt0XHhDvBTb1nHx993Cf+05yAPPH+01eWIiDRdR4Y7wO9e/Ta2XtTPb939GN9+9tVWlyMi0lQdG+69XTF3/8+f4K0XD/Db//A49z13pNUliYg0TceGO8BFK3r50m+8m0sHl/Pxu4a47XsvtrokEZGm6OhwB1i9vJvdn3wvV1+2nlv+9Xn+7N69jE4WW12WiEhDdXy4A3QXIm77b+/i+ndv5m8ffImf/T/f42uPHqCkc9CISIe6IMIdkkMkP/8rP87Xf/Mn2bCyj89+4yk+dOt/8OALI60uTUSk7i6YcK/YtmUN3/ytn+Kv/usVnJ0scsOdj3DDnY/w/RePUSyVW12eiEhdWDucg2Xbtm0+NDTU9PedKJb48vf3c+v9+zg9XmTt8m52XL6Rj2zbxNsvHsDMml6TiMhCmdked9+WOe9CDveKMxNFHnxhhG899Qr3PXeEqZIzONDD1Zet511vWs32S9eyYWWvwl5E2orCfRGOnZngO88d4T/2jfDA8yOMTSXnp1nX3807NqwItwHefvEK3jzYT3fhghvZEpE2oXBfolLZ2Xv4NHv2n+DpQ6d4/tXTvHDkDJPFZGy+KzbePNjP1vUDbFrdF27L2LS6j42r+ujtilv8LxCRTnaucC80u5g8iSPjxzau5Mc2rqy2FUtlXnrtLHsPn2bv4dfZe/g0Tx44yb8+c5ipUu2Gcu3ybi5e2cvFK3pZv7KX9QO9XLSih/UrerhooJeLBnpYvbybrli9fxGpL4X7IhXiiLeuH+Ct6wfYcfl0e6nsHDk9zqGTYxw8McqB42McPjXOq6fGeOXUOI8fOMnxs5OZr7mit8Da/h7WLu9mzfJu1vYn96uXdbOyr4tV4b5yW9FXoK8r1j4AEZmTwr1O4sh4w6o+3rCqj3dvWZO5zGSxzMiZCY6eHufI6QlGXh/n2NlJjp+dTO7PTLL/2CiP/egEJ0anzvkjq67Y6O8p0N9boL+ni4EwvbynQH9PgYHeZAOwrDu59XUXwn3Msq6YZd0F+rqjpL0rae8pRNpgiHQIhXsTdRciNq5KxuPnUy47r08UOTU6xamx5HZybJLTY0VOjyePz04UeX08uZ2ZmGLk9Ql++NpZzkwUOTNerO4MXqg4MnoLEX3dMb1dSdh3xRE9hYjuMN1diOiOI7oKET3xjPYwL31fO8/CfRzmJY97Ml67O05uUaSNjchSKNzbVBRZdRhmqcplZ2yqxOhkibHJEqNTxenpyRKjk8XqdLJckfGpMmNTJcYnS0wUy0yWykwWp29nJorJdKp9qjJdKs/a73C+umKrDf45NjbdszZE0xuSroLRE55biCMKkVGIjUJkxFFUna7MiyOjK07mdYXHyTIRceVxZESRVZefbo+IzYjDa0Y2vaxIMzUk3M3sGuAvgRj4e3f/fCPeR84tiozlPclQTbOUy85UOR38HoK/xGTRZ20UKhuQqdQGo9qeMW/WRiU8Hh0tMllyJoul8Byf9ZxWMiMJ/Vkbhog4ombDUV3Gko1KHFn1uen56Q1KzYYmY+MSh/eMbfo+jkhNJ8uml4sjqm1x6rVrnlNtY1Zb+jXTr5V+zep05TVmtWmjuFR1/19vZjHw18DPAQeBR81st7s/V+/3kvYTRUZPFNNTaK/DQN2dYtkplZ2pUjncJ4+L5TLF0uz5lfZS2ZkqO8XQXk69VrLc9HTlcbnaXqZUhlK5nDx2pxTeq/o6pdBe89xy5utPFsvTzw21TT+3TLnMrOdWaimH5fJ2vrw4YwMyc+MQZWw4KxvH9LeneEZb+ltZITa6Kvdx8u2vECff3gpx7fxKe1ccJfu1egr09yT7svpDh2r1sq6W7sNqRJfuPcCwu78EYGZfAXYACndpGTMLQzxc8L8/cE8CvpQK/JInG4HpaaobolJ1ozC9kSnXtM39WtX5s15/5ntSbSuVZ8wPr5F+/+yak9cppTZu1Q1c2BgWy2XGi9OvW9moF8OQYrGc3E+VytXllzrUuGFlL/0L+Nb8O1dt5Rff+YYlvce5NCLcNwIHUo8PAj8xcyEzuwm4CeCNb3xjA8oQkSxmRmxJj1jm56lvVZXQnwrf6qZK5er+qzMTJUYnipydLHHi7CRPHjxJeQE/Ej2f/Wrn0rIdqu5+O3A7JL9QbVUdIiLnYmEop5Czb32N+GnkIWBz6vGm0CYiIk3SiHB/FNhqZpeYWTdwPbC7Ae8jIiJzqPuwjLsXzeyTwLdJDoW8092frff7iIjI3Boy5u7u9wL3NuK1RURkfjodoYhIB1K4i4h0IIW7iEgHUriLiHSgtrjMnpmNAPuX+PR1wGt1LKde2rGudqwJ2rMu1bRw7VhXO9YE9a/rTe4+mDWjLcL9fJjZ0FzXEGyldqyrHWuC9qxLNS1cO9bVjjVBc+vSsIyISAdSuIuIdKBOCPfbW13AHNqxrnasCdqzLtW0cO1YVzvWBE2sK/dj7iIiMlsn9NxFRGQGhbuISAfKdbib2TVm9gMzGzazm5v4vpvN7AEze87MnjWzT4X2PzazQ2b2RLhdm3rOH4Q6f2BmP9/A2l42s6fD+w+FtjVmdp+Z7Qv3q0O7mdmtoa6nzOzKBtTzttT6eMLMTpvZp1uxrszsTjM7ambPpNoWvW7MbGdYfp+Z7WxATX9hZs+H9/2mma0K7VvMbCy1zv4m9Zx3hc99ONS95MsszVHToj+vev//nKOur6ZqetnMngjtzVpXc2VBS/+ugOQSUnm8kZxO+EXgUqAbeBK4rEnvvQG4MkwPAC8AlwF/DPxexvKXhfp6gEtC3XGDansZWDej7c+Bm8P0zcAtYfpa4F8AA7YDDzfhM3sVeFMr1hXwfuBK4JmlrhtgDfBSuF8dplfXuaargUKYviVV05b0cjNe55FQp4W6P1jnmhb1eTXi/2dWXTPm/1/gj5q8rubKgpb+Xbl7rnvu1Qtxu/skULkQd8O5+2F3fyxMvw7sJbl27Fx2AF9x9wl3/yEwTFJ/s+wAdoXpXcB1qfa7PPEQsMrMNjSwjquAF939XL9Gbti6cvcHgeMZ77eYdfPzwH3uftzdTwD3AdfUsyZ3/467F8PDh0iuZjanUNcKd3/Ik6S4K/XvqEtN5zDX51X3/5/nqiv0vj8K/OO5XqMB62quLGjp3xXke1gm60Lc5wrYhjCzLcAVwMOh6ZPh69adla9iNLdWB75jZnssuQg5wHp3PxymXwXWt6AuSK7Klf7P1+p1BYtfN82u73+Q9PQqLjGzx83s383sfalaDzahpsV8Xs1eT+8Djrj7vlRbU9fVjCxo+d9VnsO95cysH/gG8Gl3Pw3cBrwZuBw4TPI1sdne6+5XAh8EPmFm70/PDL2Vph//asklFz8M/FNoaod1VaNV62YuZvY5oAjcHZoOA2909yuAzwD/YGYrmlRO231eM/watR2Hpq6rjCyoatXfVZ7DvaUX4jazLpIP8253/2cAdz/i7iV3LwN/x/RwQtNqdfdD4f4o8M1Qw5HKcEu4P9rsukg2No+5+5FQX8vXVbDYddOU+szsN4BfAH49hANh6ONYmN5DMqb91vD+6aGbute0hM+raZ+jmRWAXwa+mqq3aesqKwtog7+rPId7yy7EHcb37gD2uvsXUu3p8epfAip79XcD15tZj5ldAmwl2alT77qWm9lAZZpkx9wz4f0re993Avek6roh7MHfDpxKfZWst5qeVavXVcpi1823gavNbHUYmrg6tNWNmV0DfBb4sLuPptoHzSwO05eSrJuXQl2nzWx7+Nu8IfXvqFdNi/28mvn/878Az7t7dbilWetqriygHf6uzmdvbKtvJHueXyDZKn+uie/7XpKvWU8BT4TbtcCXgadD+25gQ+o5nwt1/oDz2Ds/T12XkhyV8CTwbGWdAGuB+4F9wL8Ba0K7AX8d6noa2NagupYDx4CVqbamryuSjcthYIpkTPPGpawbknHw4XD7WANqGiYZf638bf1NWPZXwuf6BPAY8Iup19lGErgvAn9F+PV5HWta9OdV7/+fWXWF9i8Bvzlj2Watq7myoKV/V+6u0w+IiHSiPA/LiIjIHBTuIiIdSOEuItKBFO4iIh1I4S4i0oEU7iIiHUjhLiLSgf4Tv01KysqkirwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKnetbUKfJyX",
        "colab_type": "code",
        "outputId": "8deda156-7782-4fc5-c20d-d5fe30375d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(s[:10])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8bb09efac8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLOPvpyTWV6E",
        "colab_type": "text"
      },
      "source": [
        "### NMF from sklearn\n",
        "\n",
        "Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements. This non-negativity makes the resulting matrices easier to inspect <br>\n",
        "\n",
        "Following image is a representation of how NMF works:\n",
        "![alt text](https://raw.githubusercontent.com/parikshit23/Computational-Linear-Algebra/master/images/nmf_doc.png) <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MArHLjRO_Wxd",
        "colab_type": "text"
      },
      "source": [
        "We imported the data with 4 Categories. But there are multiple sub categories in each topic and there is some overlap between topics like Atheism and Religion. So there is no one correct option to choose the number of topics. \n",
        "\n",
        "For further copmutations we are using number of topics as 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PlHdpJehH-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m,n=vectors.shape\n",
        "d=5  # num topics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFdVcEP5wGjv",
        "colab_type": "text"
      },
      "source": [
        "The vectors matrix has the shape as (2034, 26576) where 2034 are the number of posts (rows of the matrix) and 26576 are the total number of words present in all posts. <br>\n",
        "\n",
        "The aim is to find two non-negative matrices (W, H) whose product approximates the non-negative matrix X. <br>\n",
        "This factorization can also be used for dimensionality reduction, source separation or topic extraction.\n",
        "\n",
        "NMF fit_transform model learns a NMF model for the data and returns the transformed data. \n",
        "\n",
        "In the following Code W1 and H1 are the output of NMF which are the two non negative matrices we want to compute. \n",
        "Where W1 is a 2034x5 where each row is one post and columns indicate the relative importance of each post to 5 topics. \n",
        "\n",
        "Where W1 is a 2034x5 where each row is one post and columns indicate the relative importance of each post to 5 topics. \n",
        "\n",
        "H1 is a 5x26576 matrix where each row is one topic and columns indicate the relatove importance of each word to the 5 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogl1WJOGhWyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ae01d75-297f-4571-a38a-bdfff947c78d"
      },
      "source": [
        "clf = decomposition.NMF(n_components=d, random_state=1)\n",
        "W1 = clf.fit_transform(vectors)\n",
        "H1 = clf.components_\n",
        "print(W1.shape,H1.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2034, 5) (5, 26576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huCk_df5yoqq",
        "colab_type": "text"
      },
      "source": [
        "Checking if W1 and H1 give us the matrix of same shape as vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vM5xMpOec55",
        "colab_type": "code",
        "outputId": "9024ba98-822c-4537-c394-956756cae458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(W1@H1).shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 26576)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mssNo_K0hCfb",
        "colab_type": "text"
      },
      "source": [
        "### Helper function to display top 8 words for all topics \n",
        "\n",
        "H1 is a 5x26576 matrix where each row is one topic and columns indicate the relative importance of each word to the 5 topics.\n",
        "\n",
        "The helper function below selects the top 8 most important word for a topic and displays them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6uS2MiXhGK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_top_words=8\n",
        "def show_topics(a):\n",
        "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
        "    topic_words = ([top_words(t) for t in a])\n",
        "    return [' '.join(t) for t in topic_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV4131kjy013",
        "colab_type": "text"
      },
      "source": [
        "Checking the top 8 words for the 5 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z85W8oeEWg5V",
        "colab_type": "code",
        "outputId": "144ce6ca-2336-4a01-f423-3f457f5211f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "show_topics(H1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jpeg image gif file color images format quality',\n",
              " 'edu graphics pub mail 128 ray ftp send',\n",
              " 'space launch satellite nasa commercial satellites year market',\n",
              " 'jesus god people matthew atheists does atheism said',\n",
              " 'image data available software processing ftp edu analysis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoxWYJk4kMKv",
        "colab_type": "text"
      },
      "source": [
        "We get topics that match the kind of clusters we would expect. We never told the algorithm how our doucments are grouped or what words belong to which topic. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27jxisoRYf_B",
        "colab_type": "text"
      },
      "source": [
        "### TF-IDF\n",
        "Topic Frequency Inverse Document Frequency is a way to normalize term counts by taking into account how often they appear in a document, how long the document is and how common/rare the term is.\n",
        "\n",
        "TF = (# occurrences of term t in document) / (# of words in documents)\n",
        "\n",
        "IDF = log(# of documents / # documents with term t in it)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ToXku9DF6xb",
        "colab_type": "text"
      },
      "source": [
        "Following is an example of TFIDD works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUXSXIjWz2Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = ['This is the first document.',\n",
        "          'This document is the second document.',\n",
        "          'And this is the third one.',\n",
        "          'Is this the first document?']\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNVe7fKhz2SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer=TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WcXjE5Sk-F3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "597c8626-816a-450c-8f46-d2d819696137"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 8)\t0.38408524091481483\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.46979138557992045\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 8)\t0.38408524091481483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6XgVOhZGGcx",
        "colab_type": "text"
      },
      "source": [
        "The vectorizer returns a sparse matrix as seen in the above cell. \n",
        "\n",
        "In a sparse matrix majority of the elements are zero and when the matrix sizes are large, storing or computing on such marices becomes a very computationaly intensive task. \n",
        "\n",
        "In the above cell only the non zero values are stored. For example:\n",
        "- the value at the location 0x1 in the matrix is 0.46979138557992045\n",
        "- the value at the location 0x2 in the matrix is 0.5802858236844359\n",
        "- there is no mention of the loication 0x4 which means that the value at that location is 0 \n",
        "\n",
        "The matrix looks like follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wkuD8NZl2Yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "360e8155-035d-49db-e971-2125ca8b1a55"
      },
      "source": [
        "print(X.todense())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]\n",
            " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
            "  0.28108867 0.         0.28108867]\n",
            " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
            "  0.26710379 0.51184851 0.26710379]\n",
            " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ww3kr0VICEL",
        "colab_type": "text"
      },
      "source": [
        "Even if the sparse matrix does not store the zero values, it inherits all the properties of the original matrix as seen below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8O0-b6Oz1oO",
        "colab_type": "code",
        "outputId": "4198c431-c3d9-4dba-d3d2-abe5d7d55941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCZt46blKg07",
        "colab_type": "text"
      },
      "source": [
        "Switching back to the newsgroup example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kWheyQ6XNhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n",
        "vectors_tfidf = vectorizer_tfidf.fit_transform(newsgroups_train.data) # (documents, vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUwrGsOzZIrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = clf.fit_transform(vectors_tfidf)\n",
        "H1 = clf.components_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dh1K7ZVpKw9",
        "colab_type": "code",
        "outputId": "c921690c-e496-4d1a-a9a2-db9bb6e70301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W1.shape,H1.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2034, 5), (5, 26576))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_-TwzJgLAEz",
        "colab_type": "text"
      },
      "source": [
        "The matrix W1 represents how important is each post to all 5 topics. Rows of the matrix represent the posts and columns represent the topics.\n",
        "\n",
        "The matrix H1 represents how important is each word to all 5 topics. Rows of the matrix represent the topics and columns represent the corpus of words.\n",
        "\n",
        "The TfidfVectorizer gives us a matrix of normalize term counts. Then after decomposing it using NMF we end up with two matices H1 and W1. \n",
        "\n",
        "As seen in the below cell, we get topics that match the kinds of clusters we would expect! This is despite the fact that this is an unsupervised algorithm - which is to say, we never actually told the algorithm how our documents are grouped. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYT5LA6LZTst",
        "colab_type": "code",
        "outputId": "7ee0399b-8a11-4bd3-d1cb-1f620bc8fbdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "show_topics(H1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['people don think just like objective say morality',\n",
              " 'graphics thanks files image file program windows know',\n",
              " 'space nasa launch shuttle orbit moon lunar earth',\n",
              " 'ico bobbe tek beauchaine bronx manhattan sank queens',\n",
              " 'god jesus bible believe christian atheism does belief']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJOWrznPZVKF",
        "colab_type": "code",
        "outputId": "2c73d9b6-5a47-4a5d-8ba1-87a2b72c7352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate the error between the two matrices\n",
        "clf.reconstruction_err_"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.712926057952785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSzW5KeOfOaG",
        "colab_type": "text"
      },
      "source": [
        "### NMF in summary\n",
        "- Fast and easy to use\n",
        "- For NMF, the matrix needs to be at least as tall as its wide, or we get and error in fit_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGIbWiAyfhl1",
        "colab_type": "text"
      },
      "source": [
        "### NMF from scratch\n",
        "\n",
        "#### Gradient Descent\n",
        "\n",
        "1. Randomly choose weights to start\n",
        "2. Loop:\n",
        "   - Use weights to calculate a prediction\n",
        "   - Calculate the derivative of the loss\n",
        "   - Update the weights\n",
        "3. Repeat step 2 lots of times, till we get decent weights\n",
        "\n",
        "<b>Key:</b> We want to decrease our loss and the derivate tells us the direction of <b>steepest descent</b>\n",
        "\n",
        "#### Stocastic gradient descent (SGD)\n",
        "\n",
        "Stochastic gradient descent is an useful optimization method (it is also the heart of deep learning, where it is used for backpropagation).\n",
        "\n",
        "For standard gradient descent, we evaluate the loss using all of our data which can be really slow. In stochastic gradient descent, we evaluate our loss function on just a sample of our data (sometimes called a mini-batch). We would get different loss values on different samples of the data, so this is why it is stochastic. It turns out that this is still an effective way to optimize, and it's much more efficient!\n",
        "\n",
        "\n",
        "Applying SGD to NMF\n",
        "\n",
        "Goal: Decompose V(mn) into <br>\n",
        "\n",
        "VWH <br> \n",
        "\n",
        "where W(md) and H(dn), W,H>=0, <br> \n",
        "and we've minimized the Frobenius norm of VWH\n",
        "\n",
        ".\n",
        "\n",
        "Approach: We will pick random positive W\n",
        "& H, and then use SGD to optimize.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grWNAssYfKvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lam=1e3\n",
        "lr=0.002\n",
        "m, n = vectors_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0GgxCIj0MaU",
        "colab_type": "text"
      },
      "source": [
        "Grad function in the following cell, calculates the gradients of the loss function, \n",
        "\n",
        "Our aim is to find 2 matrices W and H such that their product is equal to M (vectors_tfidf (tfidf value_matrix))\n",
        "\n",
        "To calculate the loss we take a product of W and H and subtract M from it. \n",
        "\n",
        "The Goal is to force the algorithm to go towards positive values of \n",
        "W and H. hence there is a panalty when W or H is negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYH_0CidUFtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu = 1e-6\n",
        "def grads(M, W, H):\n",
        "    R = W@H-M\n",
        "    return R@H.T + penalty(W, mu)*lam,W.T@R + penalty(H, mu)*lam # dW, dH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRbNCQsp2K9M",
        "colab_type": "text"
      },
      "source": [
        "The penalty function checks if the values of a matrix are greater than 0. If the value is greater than 0 then there is no penalty. \n",
        "\n",
        "If the value is less than 0 then "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFvCkMMKUpZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def penalty(M, mu):\n",
        "    return np.where(M>=mu,0, np.min(M - mu, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK8OFwrg0eV0",
        "colab_type": "text"
      },
      "source": [
        "The update function uses the grad function defined above to calculate the derivatives of the gradients by applying the appropriate penalty.\n",
        "\n",
        "These derivatives are then multiplied by the learning rate (lr) and againg fed back into the algorithm to calculate the new graidents\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiNr6KHuU0Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upd(M, W, H, lr):\n",
        "    dW,dH = grads(M,W,H)\n",
        "    W -= lr*dW; H -= lr*dH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd8VTS6F1DIr",
        "colab_type": "text"
      },
      "source": [
        "The report method gives us a sense of how the algorithm is progressing. <br>\n",
        "Ideally we want the first term  np.linalg.norm(M-W@H) to reduce after every iteration. <br>\n",
        "\n",
        "The next two terms W.min(), H.min() help us see if the values of the matrices are non negative. <br> \n",
        "For initial few iterations the values might be negative, but eventually we should end up we non negatove minimum values of W and H. <br> \n",
        "\n",
        "The last two terms (W<0).sum(), (H<0).sum() help us to see how many values in the matrices W and H are negative. This number should go down with every iteration as the algorithm penalises negative terms and pushes itself to return positive values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9QIZ-0uVJZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report(M,W,H): \n",
        "    print(np.linalg.norm(M-W@H), W.min(), H.min(), (W<0).sum(), (H<0).sum(), (penalty(W, mu)*lam).sum(),(penalty(H, mu)*lam).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxI2OlV5VctT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = np.abs(np.random.normal(scale=0.01, size=(m,d)))\n",
        "H = np.abs(np.random.normal(scale=0.01, size=(d,n)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFnJ8BXrKTra",
        "colab_type": "text"
      },
      "source": [
        "Checking the error before we do our first iteration. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjyA_YM6Vxfl",
        "colab_type": "code",
        "outputId": "cc9ca3b9-f13c-4085-d0cd-9d927aaf56b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "report(vectors_tfidf,W,H)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44.42497301489932 3.708991553498469e-06 1.0554688842057402e-08 0 0 0.0 -0.004366278603203276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VRLi4nQKzld",
        "colab_type": "text"
      },
      "source": [
        "updating the weights after first iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqx91FhQXF0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upd(vectors_tfidf,W,H,lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm9t2bj4XFsR",
        "colab_type": "code",
        "outputId": "93cb3057-7ae4-4e07-adc7-7d15ae82e911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "report(vectors_tfidf, W, H)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44.42337484433614 -0.00014984574822973307 -1.3638379091317415e-05 25 50 -2.029339137047133 -0.2500054111951147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L69k8tk5K4dp",
        "colab_type": "text"
      },
      "source": [
        "As seen above the error has reduced slightly. \n",
        "\n",
        "Running the above calculation for 500 iterations..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtb3S9bj_ZPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjCQUjtKWXm-",
        "colab_type": "code",
        "outputId": "67b0c364-f86b-4da9-f67a-0d5b03fb6405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "start = time.time()\n",
        "for i in range(500): \n",
        "    upd(vectors_tfidf,W,H,lr)\n",
        "    if i % 10 == 0: report(vectors_tfidf,W,H)\n",
        "end = time.time()\n",
        "print(\"Time taken for 500 iterations is:\", end-start)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44.42183595299505 -0.0001782299188942912 -1.0592738330121432e-05 29 85 -3.7530216426663747 -0.4255857784881747\n",
            "44.40899170513983 -0.0001413479084082155 -1.6425150363689896e-05 77 432 -9.169390484513496 -1.8867914905000822\n",
            "44.39931807710828 -0.00013576505179038214 -1.4483794204468436e-05 150 677 -15.310921961399929 -2.7170635041681614\n",
            "44.39152595235271 -0.00012031589611032813 -1.3146750624956139e-05 131 881 -13.089322056833236 -3.442339005446358\n",
            "44.38482925975928 -9.555841497318218e-05 -1.2546136905181612e-05 179 1112 -16.4335315497529 -4.207160507568509\n",
            "44.37876775215958 -8.16698817491048e-05 -1.2244607805145454e-05 152 1378 -10.646629751284683 -5.136510154302495\n",
            "44.3730360622559 -8.138705989067327e-05 -1.226855934866322e-05 150 1635 -9.123657624089715 -6.036632171144255\n",
            "44.367449305054954 -7.839437027747326e-05 -1.2414262408141464e-05 126 1892 -7.344244532276672 -7.012064444201942\n",
            "44.361880405700326 -6.109610205572367e-05 -1.2642257390532697e-05 160 2175 -8.993023776904847 -8.202273114762491\n",
            "44.3562498916207 -6.299230746072928e-05 -1.2943542131775747e-05 137 2517 -7.1585170935805795 -9.667968231595617\n",
            "44.35050128737097 -5.773892386654632e-05 -1.3300627246897724e-05 150 2882 -7.8595167528829615 -11.319426522248726\n",
            "44.34460343203346 -5.330051754838646e-05 -1.370612032739768e-05 122 3302 -5.609403250770517 -13.32721510287485\n",
            "44.33853593849888 -4.91346654820548e-05 -1.4149735742213101e-05 120 3779 -5.09936596980209 -15.533221107892055\n",
            "44.33229290042114 -4.526430325290234e-05 -1.4622084207320092e-05 125 4275 -4.664239635349603 -18.107984461307904\n",
            "44.3258755554202 -4.160799278779924e-05 -1.5119527992348661e-05 98 4791 -3.669809581463478 -21.073832501148157\n",
            "44.319292653299726 -3.823595816167521e-05 -1.563350658632465e-05 102 5366 -3.6782283404460463 -24.59548921495238\n",
            "44.31255996398497 -3.512815710797634e-05 -1.6235691530511412e-05 107 5890 -3.5892829441363507 -28.533550826785056\n",
            "44.305696888637726 -3.225849722246137e-05 -1.9172654519259126e-05 94 6472 -2.939966425278169 -32.839438244173145\n",
            "44.29872747853577 -2.9934166265439162e-05 -2.160698605100707e-05 100 7034 -2.801197634111159 -37.49408667415681\n",
            "44.2916785346021 -3.5393596720702234e-05 -2.2161068694764748e-05 109 7638 -3.478660585305803 -42.85467496995787\n",
            "44.284579002363785 -2.8090012226430264e-05 -2.270453931233565e-05 118 8240 -3.0654913644235426 -48.28706631219217\n",
            "44.27746007732524 -3.260968261710792e-05 -2.323250194986057e-05 111 8794 -2.9875694436286477 -53.77539976990239\n",
            "44.27035215089323 -3.0057747187398258e-05 -2.373941361969651e-05 104 9449 -2.417128023952205 -60.291362504672456\n",
            "44.263287432076034 -2.618379578591399e-05 -2.4219967196536917e-05 132 10084 -3.3673663504363933 -66.84164822860807\n",
            "44.256296744462624 -2.4325051618694133e-05 -2.523858486105118e-05 116 10785 -2.9049064086477907 -74.20723538746337\n",
            "44.249408973462636 -2.586359285701382e-05 -2.5665224337989387e-05 115 11492 -2.81181098248537 -82.11318727284623\n",
            "44.24265154820155 -3.5512832237100965e-05 -2.6055651193757832e-05 131 12149 -3.8071755642831526 -89.52875686093752\n",
            "44.236049040459285 -2.566890068060839e-05 -2.8347346583626905e-05 102 12808 -2.723216038526952 -96.54126307034262\n",
            "44.229622449391435 -4.1886785716542025e-05 -2.8686725229042445e-05 81 13473 -1.8429888605858271 -104.64791326032328\n",
            "44.22339017656018 -3.2163353098322564e-05 -2.9746749048508867e-05 119 14118 -3.684813081765759 -112.75230174024641\n",
            "44.21736741920923 -3.546340960225956e-05 -3.0572044578201595e-05 97 14761 -2.968511024880526 -120.8575823509598\n",
            "44.2115643535507 -2.699554172740289e-05 -3.0943123232725956e-05 115 15400 -2.670469679866777 -128.77026502767362\n",
            "44.20598839727515 -2.9940741657749644e-05 -3.128059185420335e-05 118 15956 -3.5197523918616076 -136.23948813617832\n",
            "44.20064192263137 -3.616952660487644e-05 -3.158555940976248e-05 100 16590 -2.494788558227951 -144.11127002311045\n",
            "44.195525985311654 -3.482171974673714e-05 -3.1858961155220496e-05 98 17117 -3.2834045579278577 -151.3795037424116\n",
            "44.190638998483486 -3.7368568774158595e-05 -3.1912465433234456e-05 116 17676 -3.6827885724398897 -158.8342226379861\n",
            "44.185974208658614 -3.747668570200868e-05 -3.188186664003015e-05 101 18228 -2.8812006920843234 -165.91931249643136\n",
            "44.18152437755128 -3.793568642546467e-05 -3.1695831402821663e-05 109 18615 -2.9744367119011046 -171.38044485340677\n",
            "44.177278610157344 -3.828644491712473e-05 -3.152690433131899e-05 116 18935 -4.136747536511282 -175.10430061533714\n",
            "44.173226386709196 -3.8715998742965274e-05 -3.115972409789421e-05 105 19381 -3.477893926964173 -180.63634383198806\n",
            "44.169354868307025 -4.704059739837549e-05 -3.0911268582909286e-05 110 19798 -4.8646545421447716 -185.4614620803147\n",
            "44.16565210544846 -4.88418167901235e-05 -3.0456772262951776e-05 124 20068 -5.04698307167665 -190.51763746859223\n",
            "44.162102167189914 -4.133917812837672e-05 -3.0122693004087323e-05 104 20566 -3.98959719110285 -195.97761036214033\n",
            "44.1586906323991 -4.830352593146545e-05 -2.961862649763138e-05 132 20815 -5.278729819491877 -199.31193558544194\n",
            "44.155401596073666 -4.4992905161429024e-05 -2.930230302100158e-05 136 21276 -5.731467921688098 -202.5323938873071\n",
            "44.15222156760216 -6.612268565047874e-05 -2.9147211316801315e-05 131 21429 -6.32195623915628 -204.5562977646903\n",
            "44.14913154752491 -5.876225420894238e-05 -2.9248364171128425e-05 157 21846 -7.263814062029343 -205.9592488024385\n",
            "44.14611704334858 -9.307675873223954e-05 -2.978352782036909e-05 133 22031 -7.5737844812899535 -208.37647436497585\n",
            "44.14315928217748 -9.802201997275783e-05 -3.090865496384521e-05 149 22373 -9.08020292775861 -207.61833914767254\n",
            "44.14024664245278 -8.046454593997805e-05 -2.671416299119655e-05 146 22615 -8.480121361104027 -209.3466121306113\n",
            "Time taken for 500 iterations is: 330.846718788147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFUKJBd4MlXt",
        "colab_type": "text"
      },
      "source": [
        "As seen above, it takes 330 seconds for 500 iterations to run. Also the error has not decresed a lot and the sum of negative values in matrix H has increased instead of decreasing. \n",
        "\n",
        "This tells us that the algorithm need more training. Which will take a lot of time considering for 500 iteration it took 263 seconds. \n",
        "\n",
        "To tackle with this issue, we use PyTorch and GPU for faster calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aix9PymXptzH",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch\n",
        "\n",
        "PyTorch is a Python framework for tensors and dynamic neural networks with GPU acceleration. Many of the core contributors work on Facebook's AI team. In many ways, it is similar to Numpy, only with the increased parallelization of using a GPU.\n",
        "\n",
        "<b> Note </b> If you are not using GPU, make sure to remove all the \".cuda()\" from the methods below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt6lvXzpWnFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.cuda as tc\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPOIx-FN5t5",
        "colab_type": "text"
      },
      "source": [
        "In Pytorch there is a functionality which allows us to keep track of variables as and when they are created. This can be activated by the code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSeceLh2m33O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def V(M):\n",
        "  return Variable(M, requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqYECzp3m5m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v=vectors_tfidf.todense()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEM0BO3WOzPF",
        "colab_type": "text"
      },
      "source": [
        "Stroring our vectros matrix as a torch tensor on GPU (using cuda command)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrdBXKSkOsNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_vectors = torch.Tensor(v.astype(np.float32)).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTfaUBhum9Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu = 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLzUnPG7O_TW",
        "colab_type": "text"
      },
      "source": [
        "Redifing the methods we used above. \n",
        "\n",
        "The key differences are that we are using .MM method of pytorch which allows for matrix multiplication \n",
        "\n",
        "Using Torch.clamp to select the maximum value\n",
        "\n",
        ".sub_ is the same as -= used in the above methods to multiply by -1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trP5H65LnBRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grads_t(M, W, H):\n",
        "    R = W.mm(H)-M\n",
        "    return (R.mm(H.t()) + penalty_t(W, mu)*lam,\n",
        "            W.t().mm(R) + penalty_t(H, mu)*lam) # dW, dH\n",
        "\n",
        "def penalty_t(M, mu):\n",
        "    return (M<mu).type(tc.FloatTensor)*torch.clamp(M - mu, max=0.)\n",
        "\n",
        "def upd_t(M, W, H, lr):\n",
        "    dW,dH = grads_t(M,W,H)\n",
        "    W.sub_(lr*dW); H.sub_(lr*dH)\n",
        "\n",
        "def report_t(M,W,H): \n",
        "    print((M-W.mm(H)).norm(2), W.min(), H.min(), (W<0).sum(), (H<0).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR4J2nj3PoiR",
        "colab_type": "text"
      },
      "source": [
        "Next we will initialise our tensors (matrix W and H) and assign random values.Same as above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWFXRp0Rn9MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_W = tc.FloatTensor(m,d)\n",
        "t_H = tc.FloatTensor(d,n)\n",
        "t_W.normal_(std=0.01).abs_(); \n",
        "t_H.normal_(std=0.01).abs_();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfUsxW-_oABC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=5; lam=100; lr=0.05"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgOdCjG8nISu",
        "colab_type": "code",
        "outputId": "8f8a13fc-2a6e-479b-defe-e76f94bc4c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "start = time.time()\n",
        "for i in range(5000): \n",
        "    upd_t(t_vectors,t_W,t_H,lr)\n",
        "    #report the values of every 100th iteration\n",
        "    if i % 100 == 0: \n",
        "        report_t(t_vectors,t_W,t_H)\n",
        "        lr *= 0.9\n",
        "end = time.time()\n",
        "\n",
        "print(\"time taken for 5000 iterations is\", end-start)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(44.3938, device='cuda:0') tensor(-0.0055, device='cuda:0') tensor(-0.0004, device='cuda:0') tensor(809, device='cuda:0') tensor(1429, device='cuda:0')\n",
            "tensor(43.7599, device='cuda:0') tensor(-0.0123, device='cuda:0') tensor(-0.0142, device='cuda:0') tensor(1338, device='cuda:0') tensor(16556, device='cuda:0')\n",
            "tensor(43.7237, device='cuda:0') tensor(-0.0055, device='cuda:0') tensor(-0.0113, device='cuda:0') tensor(1594, device='cuda:0') tensor(15555, device='cuda:0')\n",
            "tensor(43.7141, device='cuda:0') tensor(-0.0059, device='cuda:0') tensor(-0.0057, device='cuda:0') tensor(1855, device='cuda:0') tensor(16481, device='cuda:0')\n",
            "tensor(43.7133, device='cuda:0') tensor(-0.0051, device='cuda:0') tensor(-0.0040, device='cuda:0') tensor(1949, device='cuda:0') tensor(16944, device='cuda:0')\n",
            "tensor(43.7126, device='cuda:0') tensor(-0.0042, device='cuda:0') tensor(-0.0050, device='cuda:0') tensor(2456, device='cuda:0') tensor(18707, device='cuda:0')\n",
            "tensor(43.7123, device='cuda:0') tensor(-0.0036, device='cuda:0') tensor(-0.0066, device='cuda:0') tensor(2496, device='cuda:0') tensor(19078, device='cuda:0')\n",
            "tensor(43.7122, device='cuda:0') tensor(-0.0036, device='cuda:0') tensor(-0.0062, device='cuda:0') tensor(2435, device='cuda:0') tensor(20166, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0046, device='cuda:0') tensor(-0.0058, device='cuda:0') tensor(2377, device='cuda:0') tensor(20206, device='cuda:0')\n",
            "tensor(43.7119, device='cuda:0') tensor(-0.0041, device='cuda:0') tensor(-0.0065, device='cuda:0') tensor(3011, device='cuda:0') tensor(23973, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3743, device='cuda:0') tensor(23353, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23326, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23325, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23321, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23316, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23311, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23308, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23307, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23293, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23287, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23285, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23281, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23277, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23272, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23261, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23257, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23253, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23253, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23253, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23252, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23252, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23251, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23250, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23250, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23250, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23250, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23250, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3744, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "tensor(43.7121, device='cuda:0') tensor(-0.0020, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(3745, device='cuda:0') tensor(23249, device='cuda:0')\n",
            "time taken for 5000 iterations is 79.82772207260132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OD5Aff0Qk7p",
        "colab_type": "text"
      },
      "source": [
        "The time taken for 500 iterations without PyTroch and GPU acceleration is around 263 seconds. \n",
        "\n",
        "Where as time taken for 5000 iterations without PyTroch and GPU acceleration is around 79 seconds. \n",
        "\n",
        "That is how much the calculations are sped up when using PyTorch and GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtVIscHGcqUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9e98d105-d133-4efe-fce4-7fbe224565ce"
      },
      "source": [
        "show_topics(t_H.cpu().numpy())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['graphics thanks files image file program windows know',\n",
              " 'ico bobbe tek beauchaine bronx manhattan sank queens',\n",
              " 'space nasa launch shuttle orbit moon lunar earth',\n",
              " 'god jesus bible believe christian atheism does belief',\n",
              " 'people don think just like objective say morality']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlDA9pA9ZCVT",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch: Autograd\n",
        "\n",
        "\n",
        "\n",
        "Above, we used our knowledge of what the gradient of the loss function was to do SGD from scratch in PyTorch. However, PyTorch has an automatic differentiation package, autograd which we could use instead. This is really useful, in that we can use autograd on problems where we don't know what the derivative is.\n",
        "\n",
        "The approach we use below is very general, and would work for almost any optimization problem.\n",
        "\n",
        "In PyTorch, Variables have the same API as tensors, but Variables remember the operations used on to create them. This lets us take derivatives.\n",
        "\n",
        "Using Autograd for NMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgYqavihYUj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lam=1e6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h23Z0Af8aPAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pW = Variable(tc.FloatTensor(m,d), requires_grad=True)\n",
        "pH = Variable(tc.FloatTensor(d,n), requires_grad=True)\n",
        "pW.data.normal_(std=0.01).abs_()\n",
        "pH.data.normal_(std=0.01).abs_();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJUKDZtFatGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report():\n",
        "    W,H = pW.data, pH.data\n",
        "    print((M-pW.mm(pH)).norm(2).data, W.min(), H.min(), (W<0).sum(), (H<0).sum())\n",
        "\n",
        "def penalty(A):\n",
        "    return torch.pow((A<0).type(tc.FloatTensor)*torch.clamp(A, max=0.), 2)\n",
        "\n",
        "def penalize(): return penalty(pW).mean() + penalty(pH).mean()\n",
        "\n",
        "def loss(): return (M-pW.mm(pH)).norm(2) + penalize()*lam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmzEZvesa-RW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = Variable(t_vectors).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCtPlLIhbHjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d90bab39-2df8-4790-b41f-659ac976c65e"
      },
      "source": [
        "opt = torch.optim.Adam([pW,pH], lr=1e-3, betas=(0.9,0.9))\n",
        "lr = 0.05\n",
        "report()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(44.4254, device='cuda:0') tensor(1.1584e-08, device='cuda:0') tensor(3.8731e-07, device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzjnHGBibUbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "47b437fd-772b-46a6-fc3a-6cff982306d1"
      },
      "source": [
        "start = time.time()\n",
        "for i in range(1000):\n",
        "    #Setting gradients as zero before every iteration \n",
        "    opt.zero_grad()\n",
        "    #Calculating the loss\n",
        "    l = loss()\n",
        "    #calculating the gradients\n",
        "    l.backward()\n",
        "    #Updating the weights \n",
        "    opt.step()\n",
        "    # Every 100 steps we decrease the learning rate\n",
        "    if i % 100 == 99: \n",
        "        report()\n",
        "        lr *= 0.9 # learning rate annealling\n",
        "end = time.time()\n",
        "\n",
        "print(\"time taken for 1000 iterations is\", end-start)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(43.7277, device='cuda:0') tensor(-0.0003, device='cuda:0') tensor(-0.0005, device='cuda:0') tensor(259, device='cuda:0') tensor(5009, device='cuda:0')\n",
            "tensor(43.7277, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(-0.0005, device='cuda:0') tensor(253, device='cuda:0') tensor(4488, device='cuda:0')\n",
            "tensor(43.7276, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(-0.0005, device='cuda:0') tensor(269, device='cuda:0') tensor(4192, device='cuda:0')\n",
            "tensor(43.7276, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(-0.0005, device='cuda:0') tensor(282, device='cuda:0') tensor(3997, device='cuda:0')\n",
            "tensor(43.7275, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(-0.0004, device='cuda:0') tensor(303, device='cuda:0') tensor(3943, device='cuda:0')\n",
            "tensor(43.7275, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(-0.0003, device='cuda:0') tensor(306, device='cuda:0') tensor(3613, device='cuda:0')\n",
            "tensor(43.7274, device='cuda:0') tensor(-0.0003, device='cuda:0') tensor(-0.0003, device='cuda:0') tensor(339, device='cuda:0') tensor(3475, device='cuda:0')\n",
            "tensor(43.7274, device='cuda:0') tensor(-0.0003, device='cuda:0') tensor(-0.0005, device='cuda:0') tensor(374, device='cuda:0') tensor(3433, device='cuda:0')\n",
            "tensor(43.7273, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(-0.0004, device='cuda:0') tensor(391, device='cuda:0') tensor(3294, device='cuda:0')\n",
            "tensor(43.7273, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(-0.0003, device='cuda:0') tensor(402, device='cuda:0') tensor(3147, device='cuda:0')\n",
            "time taken for 1000 iterations is 26.70018434524536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96x06rAZllgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "290a2756-9d12-45f7-b0f0-5cdf6b3370a2"
      },
      "source": [
        "h = pH.data.cpu().numpy()\n",
        "show_topics(h)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['graphics thanks files image file program know windows',\n",
              " 'god jesus people don bible just say believe',\n",
              " 'objective morality moral values think subjective people science',\n",
              " 'space nasa launch shuttle moon orbit lunar earth',\n",
              " 'ico bobbe tek bronx beauchaine manhattan sank queens']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKmOopPwqjis",
        "colab_type": "text"
      },
      "source": [
        "## Truncated SVD\n",
        "\n",
        "To further reduce the time required for calculating the SVD we can use Truncated SVD. In Truncated SVD we are just interested in the vectors corresponding to the largest singular values. The Visual representation of truncated SVD is as follows:\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/parikshit23/Computational-Linear-Algebra/master/images/truncated_svd.png) <br>\n",
        "\n",
        "<b>The Truncated SVD helps to overcome the following short commings:</b>\n",
        "\n",
        "- Matrices are \"stupendously big\"\n",
        "- Data is often missing or inaccurate and hence why spend additonal computational resources when the impricision of input limits the precision of the output\n",
        "- Data transfer now plays a major role in time of algorithms. Techniques the require fewer passes over the data may be substantially faster, even if they require more flops (flops = floating point operations aka more steps for calculation).\n",
        "\n",
        "<b>Advantages of randomized algoriths:</b>\n",
        "- They are inherently stable\n",
        "- Performance of the algorithm does not depend on the subtle properties of the matrix\n",
        "- Matrix-vector products can be done in parallel\n",
        "\n",
        "<b> Randomized SVD </b>\n",
        "\n",
        "Reminder: full SVD is slow. Following is the calculation we did above using Scipy's Linalg SVD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0_QGhxvqYbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b027195-86e8-41d7-eeb1-a4d69030b33e"
      },
      "source": [
        "vectors.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 26576)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cB-8t7irLnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ff93d257-38ab-4d17-fb02-b713f664341f"
      },
      "source": [
        "%time U,s,Vh = linalg.svd(vectors,full_matrices = False)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 14s, sys: 3.66 s, total: 1min 17s\n",
            "Wall time: 40.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaD2o9_Brc5v",
        "colab_type": "text"
      },
      "source": [
        "The above SVD computation took 40.4 seconds to execute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nssAzds5rU0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c67cab0d-dcb3-4f8f-ff81-9813f467623c"
      },
      "source": [
        "print(U.shape,s.shape,Vh.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2034, 2034) (2034,) (2034, 26576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvIUU1dHrqwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3319cf83-5dcc-45c4-ee0a-6b6f480514b2"
      },
      "source": [
        "%time U,s,Vh = decomposition.randomized_svd(vectors,5)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.8 s, sys: 1.53 s, total: 12.3 s\n",
            "Wall time: 8.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPrGtWW6r6W7",
        "colab_type": "text"
      },
      "source": [
        "The randomized SVD took only 8 seconds to exucte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YrRzdZmr46C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50d82781-c2e9-4709-fd4d-6aeb5bd16755"
      },
      "source": [
        "print(U.shape,s.shape,Vh.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2034, 5) (5,) (5, 26576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lUqyHM8sFzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f33f4ffd-7a5e-4322-c575-8e8fc7a77346"
      },
      "source": [
        "show_topics(Vh)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jpeg image edu file graphics images gif data',\n",
              " 'jpeg gif file color quality image jfif format',\n",
              " 'space jesus launch god people satellite matthew atheists',\n",
              " 'jesus god matthew people atheists atheism does graphics',\n",
              " 'image data processing analysis software available tools display']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy5AQN9vxEOt",
        "colab_type": "text"
      },
      "source": [
        "## Implementing our own Randomized SVD\n",
        "\n",
        "The first step is to find a matrox Q that has r orthonormal columns such that <br> A QQ<sup>T</sup>A\n",
        "\n",
        "The thing to note here is that A is a mxn matrix and Q is a smaller mxr matrix. \n",
        "\n",
        "In this case Q.Q<sup>T</sup> wont be a identity matrix, because for it to be an identity matrix bothe olumns and rows of the matrix Q must be orthonormal. which they are not.\n",
        "\n",
        "So Q<sup>T</sup>A can be represented by a matrix B with shape rxn. <br>\n",
        "B = Q<sup>T</sup>A\n",
        "\n",
        "This matrix B of shape rxn is much smaller than A and we can calculate the SVD of matrix B which will be much faster than calculatin the SVD of matrix A. \n",
        "\n",
        "We plug the value of SVD of B which is qual to SV<sup>T</sup> in the above equation of A such as \n",
        "\n",
        "A  Q(SV<sup>T</sup>) \n",
        "\n",
        "Thus we have a low rank approximation of A \n",
        "\n",
        "\n",
        "## How do we find Q\n",
        "(in step 1)?\n",
        "\n",
        "To estimate the range of A\n",
        ", we can just take a bunch of random vectors wi, evaluate the subspace formed by Awi. We can form a matrix W with the wi as it's columns. Now, we take the QR decomposition of AW=QR, then the columns of Q form an orthonormal basis for AW, which is the range of A. Since the matrix AW of the product has far more rows than columns and therefore, approximately, orthonormal columns. This is simple probability - with lots of rows, and few columns, it's unlikely that the columns are linearly dependent.<br>\n",
        "\n",
        "## The QR Decomposition\n",
        "\n",
        "For now, you just need to know that A=QR, where Q consists of orthonormal columns, and R is upper triangular. \n",
        "\n",
        "## How should we choose r?\n",
        "\n",
        "Suppose our matrix has 100 columns, and we want 5 columns in U and V. To be safe, we should project our matrix onto an orthogonal basis with a few more rows and columns than 5 (let's use 15). At the end, we will just grab the first 5 columns of U and V\n",
        "\n",
        "So even although our projection was only approximate, by making it a bit bigger than we need, we can make up for the loss of accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JwNb56SsOxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import linalg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RQGxbcZLmEG",
        "colab_type": "text"
      },
      "source": [
        "The following method randomized_range_finder finds an orthonormal matrix whos range approximates the range of A. To do so, we will use the LU and QR factorizations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohTthmi4LjWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computes an orthonormal matrix whos range approximates the range of A\n",
        "def randomized_range_finder(A,size,n_iter=5):\n",
        "  Q = np.random.normal(size = (A.shape[1],size))\n",
        "\n",
        "  for i in range (n_iter):\n",
        "    Q,_=linalg.lu(A@Q,permute_l=True)\n",
        "    Q,_=linalg.lu(A.T@Q,permute_l=True)\n",
        "  Q,_=linalg.qr(A@Q,mode='economic')\n",
        "  return Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sj81Zmgue0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomized_svd(M, n_components, n_oversamples=10, n_iter=4):\n",
        "    \n",
        "    n_random = n_components + n_oversamples\n",
        "    \n",
        "    Q = randomized_range_finder(M, n_random, n_iter)\n",
        "    \n",
        "    # project M to the (k + p) dimensional space using the basis vectors\n",
        "    B = Q.T @ M\n",
        "    \n",
        "    # compute the SVD on the thin matrix: (k + p) wide\n",
        "    Uhat, s, V = linalg.svd(B, full_matrices=False)\n",
        "    del B\n",
        "    U = Q @ Uhat\n",
        "    \n",
        "    return U[:, :n_components], s[:n_components], V[:n_components, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Sb27o4utfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u, s, v = randomized_svd(vectors, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9nAVCAwuv_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "769ce4e2-982d-49e4-92a0-9bcb1c9d312c"
      },
      "source": [
        "%time u, s, v = randomized_svd(vectors, 5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.41 s, sys: 816 ms, total: 6.22 s\n",
            "Wall time: 4.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fCGVlsQu4mq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5746a53c-90eb-4f73-d075-38c8bb2c2fc3"
      },
      "source": [
        "u.shape, s.shape, v.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2034, 5), (5,), (5, 26576))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx-M5KIKu7AQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f6ad9943-23e4-4807-89de-d44d29622b40"
      },
      "source": [
        "show_topics(v)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jpeg image edu file graphics images gif data',\n",
              " 'edu graphics data space pub mail 128 3d',\n",
              " 'graphics edu pub mail 128 3d ray ftp',\n",
              " 'jesus god matthew people atheists atheism does graphics',\n",
              " 'image data processing analysis software available tools display']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMvIXe_eu8L7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "df9a221a-e151-48ed-b5f6-fccd71017fad"
      },
      "source": [
        "%time u, s, v = decomposition.randomized_svd(vectors, 5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.91 s, sys: 1.43 s, total: 11.3 s\n",
            "Wall time: 7.83 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}